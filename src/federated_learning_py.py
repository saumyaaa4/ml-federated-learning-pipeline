# -*- coding: utf-8 -*-
"""federated_learning.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16PVNjU3cWO9UWTxLDN-xpccQizgL8v_R
"""

!pip install tensorflow tensorflow-federated

import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf

# ---------------------------
# Create images folder
# ---------------------------
if not os.path.exists("images"):
    os.makedirs("images")

# ---------------------------
# Load MNIST
# ---------------------------
(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()

train_images = train_images / 255.0
test_images = test_images / 255.0

# ---------------------------
# Split data into clients
# ---------------------------
NUM_CLIENTS = 5
client_images = np.array_split(train_images, NUM_CLIENTS)
client_labels = np.array_split(train_labels, NUM_CLIENTS)

# ---------------------------
# Model definition
# ---------------------------
def create_model():
    model = tf.keras.Sequential([
        tf.keras.layers.Flatten(input_shape=(28,28)),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dense(10, activation='softmax')
    ])
    model.compile(
        optimizer='adam',
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

# ---------------------------
# Federated Averaging
# ---------------------------
def average_weights(models):
    avg_weights = list()
    for weights in zip(*[model.get_weights() for model in models]):
        avg_weights.append(np.mean(weights, axis=0))
    return avg_weights

# ---------------------------
# Training
# ---------------------------
ROUNDS = 5
global_model = create_model()
accuracy_history = []

for round_num in range(ROUNDS):
    print(f"\nRound {round_num+1}")

    local_models = []

    # Train each client locally
    for i in range(NUM_CLIENTS):
        local_model = create_model()
        local_model.set_weights(global_model.get_weights())
        local_model.fit(client_images[i], client_labels[i],
                        epochs=1, batch_size=32, verbose=0)
        local_models.append(local_model)

    # Average client weights
    new_weights = average_weights(local_models)
    global_model.set_weights(new_weights)

    # Evaluate global model
    loss, acc = global_model.evaluate(test_images, test_labels, verbose=0)
    accuracy_history.append(acc)
    print(f"Global Accuracy: {acc:.4f}")

# ---------------------------
# Plot Accuracy
# ---------------------------
plt.plot(range(1, ROUNDS+1), accuracy_history, marker='o')
plt.title("Federated Learning Global Accuracy")
plt.xlabel("Rounds")
plt.ylabel("Accuracy")
plt.grid()
plt.savefig("images/accuracy_plot.png")
plt.show()

# ---------------------------
# Save Global Model
# ---------------------------
global_model.save("global_federated_model.h5")
print("Global model saved as global_federated_model.h5")

!pip install seaborn

from sklearn.metrics import confusion_matrix
import seaborn as sns

# ---------------------------
# Confusion Matrix
# ---------------------------
predictions = global_model.predict(test_images)
predicted_labels = np.argmax(predictions, axis=1)

cm = confusion_matrix(test_labels, predicted_labels)

plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.savefig("images/confusion_matrix.png")
plt.show()

print(globals().keys())

from sklearn.metrics import classification_report

print(classification_report(test_labels, predicted_labels))

print(classification_report(test_labels, predicted_labels))

import matplotlib.pyplot as plt

rounds = range(1, len(accuracy_history) + 1)

plt.plot(rounds, accuracy_history)
plt.xlabel("Federated Rounds")
plt.ylabel("Global Accuracy")
plt.title("Federated Learning Convergence")
plt.show()

global_model.save("global_federated_model.keras")